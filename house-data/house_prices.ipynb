{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "target = train_data.SalePrice\n",
    "\n",
    "# We use the simplest approach and drop the NA values\n",
    "# since here we are concerned about categorical variables\n",
    "\n",
    "cols_with_missing = [col for col in train_data.columns if train_data[col].isnull().any()]\n",
    "candidate_train_predictors = train_data.drop(['Id', 'SalePrice'] + cols_with_missing, axis=1)\n",
    "candidate_test_predictors = test_data.drop(['Id'] + cols_with_missing, axis=1)\n",
    "\n",
    "low_cardinality_cols = [cname for cname in candidate_train_predictors.columns if \n",
    "                                candidate_train_predictors[cname].nunique() < 10 and\n",
    "                                candidate_train_predictors[cname].dtype == \"object\"]\n",
    "\n",
    "numeric_cols = [cname for cname in candidate_train_predictors.columns if \n",
    "                                candidate_train_predictors[cname].dtype in ['int64', 'float64']]\n",
    "my_cols = low_cardinality_cols + numeric_cols\n",
    "train_predictors = candidate_train_predictors[my_cols]\n",
    "test_predictors = candidate_test_predictors[my_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotConfig     object\n",
       "BsmtFinSF1     int64\n",
       "PoolArea       int64\n",
       "MoSold         int64\n",
       "MSSubClass     int64\n",
       "LotShape      object\n",
       "CentralAir    object\n",
       "Condition1    object\n",
       "Street        object\n",
       "Utilities     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictors.dtypes.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_training_predictors = pd.get_dummies(train_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error when Dropping Categoricals:18656\n",
      "Mean Absolute Error with One-hot Encoding:18210\n"
     ]
    }
   ],
   "source": [
    "# investigate the effect of adding categorical variables to our model \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def get_mae(X, y):\n",
    "    return -1 * cross_val_score(RandomForestRegressor(50),\n",
    "                               X,y, scoring='neg_mean_absolute_error').mean()\n",
    "\n",
    "predictors_without_categoricals = train_predictors.select_dtypes(exclude=['object'])\n",
    "\n",
    "mae_without_categoricals = get_mae(predictors_without_categoricals, target)\n",
    "\n",
    "mae_one_hot_encoded = get_mae(one_hot_encoded_training_predictors, target)\n",
    "\n",
    "print('Mean Absolute Error when Dropping Categoricals:'\n",
    "      + str(int(mae_without_categoricals)))\n",
    "print('Mean Absolute Error with One-hot Encoding:'\n",
    "     + str(int(mae_one_hot_encoded)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn is sensitive to the ordering of columns, so if the training dataset and test datasets get misaligned, the results will be nonsense! This could happen if a categorical had a different number of values in the training data vs the test data. \n",
    "Ensure the test data is encoded in the same manner as the training with the align command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_training_predictors = pd.get_dummies(train_predictors)\n",
    "one_hot_encoded_test_predictors = pd.get_dummies(test_predictors)\n",
    "\n",
    "final_train, final_test = one_hot_encoded_training_predictors.align(one_hot_encoded_test_predictors,\n",
    "                                                                   join='left',\n",
    "                                                                   axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
